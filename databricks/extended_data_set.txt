###################
Create Customer Demographics Dataset
#########################

from pyspark.sql import SparkSession
from pyspark.sql.types import *
import random
from datetime import datetime

spark = SparkSession.builder.appName("CustomerData").getOrCreate()

# Customer demographics data
customer_data = []
customer_ids = [f"CUST{1000 + i}" for i in range(25)]
membership_levels = ['Basic', 'Silver', 'Gold', 'Platinum']
cities = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']
genders = ['Male', 'Female', 'Other']

for i in range(25):
    join_date = datetime(2022, 1, 1) + timedelta(days=random.randint(1, 730))
    customer_data.append({
        'CustomerID': customer_ids[i],
        'OrderID': f'ORD{1000 + i}',  # Matching order IDs from sales data
        'Name': f'Customer {i+1}',
        'Age': random.randint(18, 70),
        'Gender': random.choice(genders),
        'City': random.choice(cities),
        'MembershipLevel': random.choices(membership_levels, weights=[0.4, 0.3, 0.2, 0.1])[0],
        'JoinDate': join_date,
        'LoyaltyPoints': random.randint(0, 5000),
        'Email': f'customer{i+1}@example.com'
    })

# Schema for customer data
customer_schema = StructType([
    StructField("CustomerID", StringType(), True),
    StructField("OrderID", StringType(), True),
    StructField("Name", StringType(), True),
    StructField("Age", IntegerType(), True),
    StructField("Gender", StringType(), True),
    StructField("City", StringType(), True),
    StructField("MembershipLevel", StringType(), True),
    StructField("JoinDate", DateType(), True),
    StructField("LoyaltyPoints", IntegerType(), True),
    StructField("Email", StringType(), True)
])

customers_df = spark.createDataFrame(customer_data, customer_schema)
customers_df.createOrReplaceTempView("customers")

display(customers_df)

# Merge sales data with customer data
combined_df = sales_df.join(
    customers_df, 
    sales_df.OrderID == customers_df.OrderID, 
    "inner"
)

#Left Join (Keep All Sales)
left_combined = sales_df.join(
    customers_df,
    sales_df.OrderID == customers_df.OrderID,
    "left"
)

left_combined.createOrReplaceTempView("all_sales_with_customer_info")


#Query Examples on Merged Data
#Sales Performance by Membership Level

membership_sales = spark.sql("""
    SELECT 
        c.MembershipLevel,
        COUNT(s.OrderID) AS OrderCount,
        ROUND(SUM(s.TotalSales), 2) AS TotalSales,
        ROUND(AVG(s.TotalSales), 2) AS AvgOrderValue,
        ROUND(SUM(s.TotalSales) * 100 / (SELECT SUM(TotalSales) FROM sales_data), 2) AS SalesPercentage
    FROM sales_data s
    JOIN customers c ON s.OrderID = c.OrderID
    GROUP BY c.MembershipLevel
    ORDER BY TotalSales DESC
""")

display(membership_sales)

# Create a temporary view
combined_df.createOrReplaceTempView("sales_with_customers")

# Show the combined schema
combined_df.printSchema()

#Customer Segmentation Analysis
customer_segments = spark.sql("""
    SELECT 
        CASE 
            WHEN c.Age < 30 THEN 'Under 30'
            WHEN c.Age BETWEEN 30 AND 50 THEN '30-50'
            ELSE 'Over 50'
        END AS AgeGroup,
        c.Gender,
        c.City,
        COUNT(DISTINCT c.CustomerID) AS CustomerCount,
        ROUND(SUM(s.TotalSales), 2) AS TotalSales,
        ROUND(AVG(s.TotalSales), 2) AS AvgSpend
    FROM sales_data s
    JOIN customers c ON s.OrderID = c.OrderID
    GROUP BY AgeGroup, c.Gender, c.City
    ORDER BY TotalSales DESC
""")

display(customer_segments)

#Product Preferences by Demographic
product_preferences = spark.sql("""
    SELECT 
        s.ProductCategory,
        c.MembershipLevel,
        c.Gender,
        COUNT(s.OrderID) AS OrderCount,
        ROUND(SUM(s.TotalSales), 2) AS TotalSales
    FROM sales_data s
    JOIN customers c ON s.OrderID = c.OrderID
    GROUP BY s.ProductCategory, c.MembershipLevel, c.Gender
    ORDER BY s.ProductCategory, TotalSales DESC
""")

display(product_preferences)
